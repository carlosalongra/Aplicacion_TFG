# Hadoop properties
#put your own local host docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' namenode
spring.hadoop.fsUri=hdfs://192.168.0.230:9000
spring.data.hadoop.fs-uri=hdfs://192.168.0.230:9000
spring.data.hadoop.hdfs-root-dir=/user/hadoop
spring.hadoop.config.fs.defaultFS=hdfs://192.168.0.230:9000
spring.hadoop.config.dfs.client.use.datanode.hostname=true
spring.hadoop.config.dfs.replication=1

# MongoDB properties
spring.data.mongodb.database=${env.MONGO_DATABASE}
spring.data.mongodb.uri=mongodb+srv://${env.MONGO_USER}:${env.MONGO_PASSWORD}@${env.MONGO_CLUSTER}
#spring.data.mongodb.uri=mongodb://${env.MONGO_USER}:${env.MONGO_PASSWORD}@ac-mkvq4bl-shard-00-00.xefdshg.mongodb.net:27017,ac-mkvq4bl-shard-00-01.xefdshg.mongodb.net:27017,ac-mkvq4bl-shard-00-02.xefdshg.mongodb.net:27017/${env.MONGO_DATABASE}?ssl=true&replicaSet=atlas-igaj28-shard-0&authSource=admin&retryWrites=true&w=majority

# Logging properties
logging.level.org.springframework=DEBUG
logging.level.org.apache.hadoop=DEBUG
logging.level.com.unik.hadoopcontroller.service.HdfsDirectService=DEBUG

# Spark properties
spark.app.name=SparkJob
spark.master=yarn
spark.deploymode=cluster