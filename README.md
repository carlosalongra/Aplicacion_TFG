# TRABAJO FIN DE GRADO

Módulo de análisis BigData On-premises

[EN] On-premises BigData analysis module

## Project information
Please note that this project only works locally, the main purpose it to demonstrate and guide how to set up a Hadoop environment with the associated front end and back end implementation. A demo video is attached, demonstrating how the front-end system operates and showcasing a word count example algorithm on uploaded files. Additionally, access to the database is private, and the credentials are not accessible to the public.

For further information, access MemoriaTFG.pdf file located in memoria/MemoriaTFG.pdf

## Project abstract  
The objective of this project is to investigate and develop a framework that enhances big data analysis capabilities and  implements a more efficient distributed file system and storage solution. To achieve this, the integration of Hadoop and Apache Spark, two powerful technologies for big data processing and analytics, was explored. The goal was to leverage Hadoop’s HDFS for scalable storage and Spark’s in-memory processing capabilities to improve data analysis performance.
UNIK (Unification of Korea) is a year-long project. During the first semester, the focus was on developing the Hadoop ecosystem and creating a user-friendly interface for file uploads to HDFS. This involved setting up the Hadoop cluster, configuring HDFS, and integrating Spark for advanced data processing. A web-based User Interface (UI) was also designed and implemented to streamline the file upload process, ensuring ease of use for researchers and analysts.

## Project build
Front-End system is developed in Angular 15

Back-End(controller) is developed in SpringBoot(Java 17)

## Authors and License
  - Carlos Alonso
  - Siaw Jia Yuin (Dana)
  - John Song

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)


